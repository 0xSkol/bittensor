{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    }
   ],
   "source": [
    "import bittensor\n",
    "import torch\n",
    "from bittensor.utils.tokenizer_utils import prep_tokenizer, set_std_token_phrases, topk_token_phrases\n",
    "from transformers import AutoModel,AutoTokenizer,AutoConfig, AutoModelForCausalLM\n",
    "from transformers import GPTNeoXForCausalLM, GPTNeoXTokenizerFast\n",
    "from bittensor._neuron.text.core_server.nucleus_impl import server \n",
    "\n",
    "dataset = bittensor.dataset(num_batches = 1000)\n",
    "inputs = next(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "axon:\n",
      "  backward_timeout: 24\n",
      "  causallm_timeout: 12\n",
      "  causallmnext_timeout: 12\n",
      "  compression: NoCompression\n",
      "  external_ip: null\n",
      "  external_port: null\n",
      "  forward_timeout: 60\n",
      "  ip: '[::]'\n",
      "  lasthidden_timeout: 12\n",
      "  max_workers: 10\n",
      "  maximum_concurrent_rpcs: 400\n",
      "  port: 8091\n",
      "  priority:\n",
      "    max_workers: 10\n",
      "    maxsize: -1\n",
      "  prometheus:\n",
      "    level: DEBUG\n",
      "  seq2seq_timeout: 36\n",
      "config: null\n",
      "dataset:\n",
      "  _mock: false\n",
      "  batch_size: 10\n",
      "  block_size: 20\n",
      "  data_dir: ~/.bittensor/data/\n",
      "  dataset_name: default\n",
      "  max_datasets: 3\n",
      "  max_directories: 250\n",
      "  no_tokenizer: false\n",
      "  num_batches: 500\n",
      "  num_workers: 0\n",
      "  save_dataset: false\n",
      "logging:\n",
      "  debug: false\n",
      "  logging_dir: ~/.bittensor/miners\n",
      "  record_log: false\n",
      "  trace: false\n",
      "metagraph:\n",
      "  _mock: false\n",
      "neuron:\n",
      "  autocast: false\n",
      "  blacklist:\n",
      "    stake: 10\n",
      "    time: 1\n",
      "  blacklist_allow_non_registered: false\n",
      "  blocks_per_epoch: 10\n",
      "  blocks_per_set_weights: -1\n",
      "  causallm: true\n",
      "  causallm_stake: 0\n",
      "  causallmnext: true\n",
      "  causallmnext_stake: 0\n",
      "  checking: true\n",
      "  clip_gradients: 1.0\n",
      "  device: cuda:2\n",
      "  disable_blacklist: false\n",
      "  disable_priority: false\n",
      "  finetune:\n",
      "    all: false\n",
      "    layer_name: null\n",
      "    num_layers: 1\n",
      "  inter_degree: nearest\n",
      "  interpolate: true\n",
      "  lasthidden: true\n",
      "  lasthidden_stake: 0\n",
      "  learning_rate: 0.01\n",
      "  local_train: false\n",
      "  metagraph_sync: 100000\n",
      "  model_name: gpt2\n",
      "  momentum: 0.8\n",
      "  name: core_server\n",
      "  no_set_weights: false\n",
      "  num_remote_loss: 20\n",
      "  padding: true\n",
      "  pretrained: true\n",
      "  remote_train: false\n",
      "  restart: false\n",
      "  seq2seq: true\n",
      "  seq2seq_stake: 0\n",
      "prometheus:\n",
      "  level: INFO\n",
      "  port: 7091\n",
      "strict: false\n",
      "subtensor:\n",
      "  _mock: false\n",
      "  chain_endpoint: null\n",
      "  network: nakamoto\n",
      "  register:\n",
      "    cuda:\n",
      "      TPB: 256\n",
      "    num_processes: null\n",
      "    output_in_place: true\n",
      "    update_interval: 50000\n",
      "    verbose: false\n",
      "wallet:\n",
      "  _mock: false\n",
      "  all_hotkeys: false\n",
      "  hotkey: default\n",
      "  hotkeys: []\n",
      "  name: default\n",
      "  path: ~/.bittensor/wallets/\n",
      "  reregister: true\n",
      "wandb:\n",
      "  api_key: default\n",
      "  directory: default\n",
      "  name: default\n",
      "  offline: false\n",
      "  project: default\n",
      "  run_group: default\n",
      "  tags: default\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    }
   ],
   "source": [
    "neox_tokenizer = GPTNeoXTokenizerFast.from_pretrained(\"EleutherAI/gpt-neox-20b\")\n",
    "gpt_tokenizer = bittensor.tokenizer()\n",
    "\n",
    "config = server.config()\n",
    "config.neuron.device = 'cuda:2'\n",
    "config.neuron.autocast = False\n",
    "# s = server( model_name='EleutherAI/gpt-neox-20b', tokenizer = neox_tokenizer, config = config)\n",
    "s = server( model_name='EleutherAI/pythia-6.7b', tokenizer = neox_tokenizer, config = config)\n",
    "s.to(s.device)\n",
    "remapping_token = s.remapping_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like \\\"fundamentalist\\\" and \\\"political\\nIslam\\\" which it claims are used by \\\"\n",
      "like \\\"fundamentalist\\\" and \\\"political\\nIslam\\\" which it claims are used by \\\"\n"
     ]
    }
   ],
   "source": [
    "inputs = next(dataset)\n",
    "tokens = remapping_token(inputs, gpt_tokenizer)\n",
    "\n",
    "print(gpt_tokenizer.decode(inputs[0]))\n",
    "print(neox_tokenizer.decode(tokens['input_ids'][0]))\n",
    "\n",
    "synapse = bittensor._synapse.TextCausalLMNext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('cuda:2', device(type='cuda', index=2))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# s.to(s.device)\n",
    "s.device, next(s.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spidermonkey?\\n\\n~~~\\nrbxbx\\nBeyond already compiling\n"
     ]
    }
   ],
   "source": [
    "inputs = next(dataset)\n",
    "print(gpt_tokenizer.decode(inputs[0]))\n",
    "message, model_out, topk_tensor = s.encode_forward_causallmnext(inputs.to(s.device))\n",
    "encoded_tensor = synapse.encode_forward_response_tensor ( topk_tensor )\n",
    "synapse.check_forward_response_tensor ( inputs, encoded_tensor )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spidermonkey?\\n\\n~~~\\nrbxbx\\nBeyond already compiling\n",
      "spidermonkey?\\n\\n~~~\\nrbxbx\\nBeyond already\n"
     ]
    }
   ],
   "source": [
    "tokens = s.token_remap(inputs, gpt_tokenizer)\n",
    "\n",
    "print(gpt_tokenizer.decode(inputs[0]))\n",
    "print(neox_tokenizer.decode(tokens['input_ids'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0, device='cuda:2'), torch.Size([10, 50432]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_out.logits[:, -1, :].isnan().sum(), model_out.logits[:, -1, :].shape\n",
    "# model_out.logits[0,0,0].isnan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.1878, -3.7446,  4.2936,  ..., -2.7502, -4.0566, -3.6009],\n",
       "         [ 2.2981, -3.4558,  5.3553,  ..., -4.2135, -4.4500, -4.6469],\n",
       "         [ 5.7284, -3.5307,  5.7618,  ..., -3.6494, -4.1912, -4.1185],\n",
       "         ...,\n",
       "         [ 5.3423, -4.5252,  7.0842,  ..., -3.8828, -3.5743, -3.9709],\n",
       "         [ 1.7014, -6.6128,  5.9407,  ..., -6.0590, -5.7725, -7.3878],\n",
       "         [ 3.6401, -2.7888,  8.5816,  ..., -3.4991, -3.0438, -3.5771]],\n",
       "\n",
       "        [[ 6.5989, -4.6633,  6.9140,  ..., -4.8257, -5.2541, -5.2388],\n",
       "         [ 4.8050, -3.0929,  4.7389,  ..., -3.3986, -3.0610, -3.5224],\n",
       "         [ 2.1787, -5.0613,  2.9622,  ..., -5.8085, -5.3384, -5.6233],\n",
       "         ...,\n",
       "         [ 3.6398, -2.7343,  3.9939,  ..., -4.1491, -3.1400, -3.4236],\n",
       "         [ 5.4346, -1.6248,  4.8129,  ..., -3.3497, -2.2994, -2.2239],\n",
       "         [ 4.0103, -2.0015,  2.9519,  ..., -3.0538, -2.3307, -2.6978]],\n",
       "\n",
       "        [[ 3.0715, -4.5028,  6.2973,  ..., -4.9415, -4.4452, -4.7350],\n",
       "         [ 5.6078, -2.9392,  6.0222,  ..., -3.2514, -4.1451, -3.1760],\n",
       "         [ 5.5711, -4.4930,  4.3598,  ..., -4.4935, -3.9297, -3.9993],\n",
       "         ...,\n",
       "         [ 4.9696, -3.7880, 11.9490,  ..., -3.3322, -3.5428, -3.2432],\n",
       "         [ 7.5419, -1.7681,  7.1580,  ..., -1.3534, -2.7266, -2.0494],\n",
       "         [ 9.8383, -3.3899,  6.2215,  ..., -3.2680, -3.3546, -3.2036]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 2.4318, -4.0999,  4.3485,  ..., -3.5378, -4.2371, -3.9097],\n",
       "         [ 3.7312, -4.4910,  5.7032,  ..., -4.9500, -5.2396, -5.0973],\n",
       "         [ 0.8225, -5.7793,  2.2498,  ..., -6.6120, -6.3332, -6.1225],\n",
       "         ...,\n",
       "         [ 2.8559, -2.7268,  5.4155,  ..., -2.9318, -3.1787, -2.5875],\n",
       "         [ 1.1532, -3.7386,  2.9591,  ..., -3.6464, -3.3244, -3.9393],\n",
       "         [ 4.8343, -0.0510, 13.0635,  ..., -0.0402,  0.5537,  0.5927]],\n",
       "\n",
       "        [[ 0.7524, -6.8412,  1.0790,  ..., -6.7087, -6.8503, -6.5767],\n",
       "         [ 2.6925, -4.0751,  6.0064,  ..., -3.5865, -4.3438, -3.9501],\n",
       "         [ 1.2892, -5.4267,  2.0399,  ..., -4.8561, -5.0473, -4.9296],\n",
       "         ...,\n",
       "         [ 6.2256, -1.7609,  4.6352,  ..., -1.3860, -2.4884, -1.7775],\n",
       "         [ 7.1804, -3.8167,  3.6346,  ..., -3.3417, -3.4106, -2.8308],\n",
       "         [ 5.6162, -2.6473,  2.7873,  ..., -2.3515, -2.0618, -2.6375]],\n",
       "\n",
       "        [[ 1.8487, -5.1484,  3.9053,  ..., -5.0421, -5.2720, -5.0184],\n",
       "         [ 3.3540, -4.4185,  1.2680,  ..., -5.3271, -5.3486, -4.4540],\n",
       "         [ 2.9520, -4.7629,  6.1195,  ..., -4.1330, -3.7638, -3.3008],\n",
       "         ...,\n",
       "         [ 4.2575, -4.4530,  5.6572,  ..., -4.6267, -4.5398, -4.9656],\n",
       "         [ 7.0262, -1.1581,  9.9825,  ..., -2.7053, -1.6150, -2.0401],\n",
       "         [ 7.7931, -1.9003,  4.2786,  ..., -2.5696, -2.0881, -3.3300]]],\n",
       "       device='cuda:2')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "with torch.no_grad():\n",
    "    _model_output = s.pre_model(\n",
    "        input_ids=tokens['input_ids'],\n",
    "        attention_mask=tokens['attention_mask'],\n",
    "        output_hidden_states=True,\n",
    "        use_cache = True\n",
    "    )\n",
    "_model_output.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden layer 0 \t num nan 0\n",
      "hidden layer 1 \t num nan 0\n",
      "hidden layer 2 \t num nan 0\n",
      "hidden layer 3 \t num nan 0\n",
      "hidden layer 4 \t num nan 0\n",
      "hidden layer 5 \t num nan 0\n",
      "hidden layer 6 \t num nan 0\n",
      "hidden layer 7 \t num nan 0\n",
      "hidden layer 8 \t num nan 0\n",
      "hidden layer 9 \t num nan 0\n",
      "hidden layer 10 \t num nan 0\n",
      "hidden layer 11 \t num nan 0\n",
      "hidden layer 12 \t num nan 0\n",
      "hidden layer 13 \t num nan 0\n",
      "hidden layer 14 \t num nan 0\n",
      "hidden layer 15 \t num nan 0\n",
      "hidden layer 16 \t num nan 0\n",
      "hidden layer 17 \t num nan 0\n",
      "hidden layer 18 \t num nan 0\n",
      "hidden layer 19 \t num nan 0\n",
      "hidden layer 20 \t num nan 0\n",
      "hidden layer 21 \t num nan 0\n",
      "hidden layer 22 \t num nan 0\n",
      "hidden layer 23 \t num nan 0\n",
      "hidden layer 24 \t num nan 0\n",
      "hidden layer 25 \t num nan 0\n",
      "hidden layer 26 \t num nan 0\n",
      "hidden layer 27 \t num nan 0\n",
      "hidden layer 28 \t num nan 0\n",
      "hidden layer 29 \t num nan 0\n",
      "hidden layer 30 \t num nan 0\n",
      "hidden layer 31 \t num nan 0\n",
      "hidden layer 32 \t num nan 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(_model_output.hidden_states)):\n",
    "    print('hidden layer', i, '\\t num nan' ,_model_output.hidden_states[i].isnan().sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   17, 27493, 29626,    13,  9938,   262,  2219, 31457,  1352,   286,\n",
       "          5125,    14,  1157,   290,   357,    88, 29006,    12,   940,  4008],\n",
       "        [ 6864,  3513, 37086,   290,   532, 42122, 12948,   850,  8968, 11655,\n",
       "         41547, 35547,   290,   481,  9585,   777, 13871,   530,  1285,   706],\n",
       "        [   78,    25,   513,    11,  2124,    25,   352,    11,   279,    25,\n",
       "           642,    92,    30,    59,    77,    18,    14, 14686,    59,    77],\n",
       "        [ 8692,  1511,    13,    59,    77,   397,    59,    77,  3103,  1851,\n",
       "           532, 37283,   357,  8692,   604,     8,   284,  2779,   642,    13],\n",
       "        [ 4895, 31815, 20598, 17241,  6601,  2404,    59,    84,   830,    23,\n",
       "            59,    84, 34215,    59,    84,   405,  1065,    59,  1648, 16344],\n",
       "        [  615,  6255,  6731,   286,   262,   440,  2536,  4066, 18389,   379,\n",
       "           617,   966,   287,   674, 16179,    13,  7879, 19990, 22210,   338],\n",
       "        [   12,   357,    16,  1343,  1105,  1343,   532,  2327,  1343,   838,\n",
       "           737,    59,    77,  2481,    59,    77,    36,  2100,  4985,   604],\n",
       "        [   66,     7,    74,     8,   796,   532,  1415, 18444,     9,    74,\n",
       "           532,  1467,    13,  3914,  2124,   796,   352,   532,  1315,    13],\n",
       "        [  271,   262,  6000,  2219,  2659,   271,   273,   286,  1478,   486,\n",
       "          3459,   290,  5946,  2598,  2598,    30,    59,    77,  1485,  3459],\n",
       "        [ 9771,  3129,   378,   288, 32590,  1954,   737,    59,    77,    12,\n",
       "            24,    59,    77,  5756,   277,     7,    67,     8,   796,   532]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16386"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 * ( 2 * 4096 + 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.2\n",
      "1.12.0+cu102\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.is_available()\n",
    "print(torch.version.cuda)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(100000016.0) == torch.tensor(100000015.0)\n",
    "# torch.tensor(100000016.0, dtype=float) == torch.tensor(100000015.0, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, torch.float64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(100000016.0).dtype, torch.tensor(100000016.0,dtype = float).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000032.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.tensor(100000026.0) + torch.tensor(100000015.0)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1234., dtype=torch.float16)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(, dtype = torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.float16.is_signed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__module__',\n",
       " '__repr__',\n",
       " '__reduce__',\n",
       " 'is_floating_point',\n",
       " 'is_complex',\n",
       " 'is_signed',\n",
       " '__doc__',\n",
       " '__hash__',\n",
       " '__str__',\n",
       " '__getattribute__',\n",
       " '__setattr__',\n",
       " '__delattr__',\n",
       " '__lt__',\n",
       " '__le__',\n",
       " '__eq__',\n",
       " '__ne__',\n",
       " '__gt__',\n",
       " '__ge__',\n",
       " '__init__',\n",
       " '__new__',\n",
       " '__reduce_ex__',\n",
       " '__subclasshook__',\n",
       " '__init_subclass__',\n",
       " '__format__',\n",
       " '__sizeof__',\n",
       " '__dir__',\n",
       " '__class__']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.float16.__dir__()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
