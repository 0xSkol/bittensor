diff --git a/bittensor/_subtensor/subtensor_impl.py b/bittensor/_subtensor/subtensor_impl.py
index 1c3faee..27e67f9 100644
--- a/bittensor/_subtensor/subtensor_impl.py
+++ b/bittensor/_subtensor/subtensor_impl.py
@@ -413,6 +413,7 @@ To run a local node (See: docs/running_a_validator.md) \n
                 If we did not wait for finalization / inclusion, the response is true.
         """
         weight_uids, weight_vals = weight_utils.convert_weights_and_uids_for_emit( uids, weights )
+        bittensor.logging.success( 'Setting weights', str(list(zip(weight_uids, weight_vals))))
         with self.substrate as substrate:
             call = substrate.compose_call(
                 call_module='SubtensorModule',
@@ -424,10 +425,10 @@ To run a local node (See: docs/running_a_validator.md) \n
             if wait_for_inclusion or wait_for_finalization:
                 response.process_events()
                 if response.is_success:
-                    bittensor.logging.success( 'Set weights', str(list(zip(weight_uids, weight_vals))))
+                    bittensor.logging.success( prefix = 'Weights Set', sufix = '<green>True</green>')
                     return True
                 else:
-                    bittensor.logging.warning( 'Failed to set weights:', str(response.error_message) )
+                    bittensor.logging.warning(  prefix = 'Weights Set', sufix = '<green>False: </green>' + str(response.error_message) )
                     return False
             else:
                 return True
diff --git a/miners/text/template_validator.py b/miners/text/template_validator.py
index 614cfb1..1103ec4 100644
--- a/miners/text/template_validator.py
+++ b/miners/text/template_validator.py
@@ -163,20 +163,20 @@ def main( config ):
 
                 # Take topk chain weights.
                 real_topk = min( config.miner.n_topk_chain_weights, metagraph.n.item() ) 
-                topk_weights, topk_uids = torch.topk( validator.chain_weights, k = real_topk )
-                normalized_topk_weights = torch.nn.functional.normalize( topk_weights - torch.min( topk_weights ), p = 1, dim = 0)
+                topk_weights, topk_uids = torch.topk( F.softmax( validator.chain_weights ), k = real_topk )
+                final_weights = torch.nn.functional.normalize( topk_weights - torch.min( topk_weights ), p = 1, dim = 0)
 
                 # Step logs.
                 info = { 'Loss': colored('{:.4f}'.format(loss.item()), 'green')}
-                for uid in range( metagraph.n.item() ):
-                    weight_grad = validator.chain_weights.grad[ uid ]
-                    info[ str(uid) ] = colored('{:.4f}'.format(normalized_topk_weights[ uid ]), 'green' if weight_grad < 0 else 'red')
+                for weight, uid_j in list(zip(final_weights.tolist(), topk_uids.tolist())):
+                    print (validator.chain_weights.grad)
+                    if weight > 0.001: info[ str(uid_j) ] = colored('{:.4f}'.format( weight ), 'green' if validator.chain_weights.grad[ uid_j ] < 0 else 'red')
                 progress_bar.set_infos( info )
 
             # ---  Set mechanism weights.
             subtensor.set_weights (
                 uids = topk_uids,
-                weights = normalized_topk_weights,
+                weights = final_weights,
                 wait_for_inclusion = False,
                 wallet = wallet,
             )    
@@ -200,8 +200,8 @@ def main( config ):
                 'Rank': metagraph.R[ uid ].item(),
                 'Incentive': metagraph.I[ uid ].item(),
             } 
-            for uid_j, val in enumerate(validator.chain_weights.tolist()):
-                wand_data[ 'w_{},{}'.format( uid, uid_j ) ] = val
+            for weight, uid_j in list(zip(final_weights.tolist(), topk_uids.tolist())):
+                if weight != 0: wand_data[ 'w_{},{}'.format( uid, uid_j ) ] = weight
             wandb.log( wand_data )
 
 if __name__ == "__main__":
